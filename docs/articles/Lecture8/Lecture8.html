<!DOCTYPE html>
<html>
  <head>
    <title>Lecture 8</title>
    <meta charset="utf-8">
    <meta name="author" content="   WILD6900 (Spring 2020)" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="WILD6900.css" type="text/css" />
    <link rel="stylesheet" href="WILD6900-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lecture 8
## Introduction to hierarchical models
### <br/><br/><br/>WILD6900 (Spring 2020)

---




## Readings

&gt; KÃ©ry &amp; Schaub 73-82

---
class: inverse, center, middle

# What are random effects?

---
## What are random effects?
&lt;br/&gt;

--
- Fixed effects are constant across observational units, random effects vary across units  
&lt;br/&gt;

--
- Fixed effects are used when you are interested in the specific factor levels, random effects are used when you are interested in the underlying population  
&lt;br/&gt;

--
- When factors levels are exhaustive, they are fixed. When they are a sample of the possible levels, they are random  
&lt;br/&gt;

--
- Random effects are the realized values of a random variable  
&lt;br/&gt;

--
- Fixed effects are estimated by maximum likelihood, random effects are estimated with shrinkage  

???

Definitions from Gelman &amp; Hill (2007) pg. 245

---
## A simple linear model

`$$\Large y_{ij} = \beta_{[j]} + \epsilon_i$$`

`$$\Large \epsilon_i \sim normal(0, \tau)$$`

--
- If `\(\beta_{[1]} = \beta_{[2]} = \beta_{[3]} = ...=\beta_{[J]}\)`

--
```
model {
  # Priors
  beta0 ~ dnorm(0, 0.33)
  tau ~ dgamma(0.25, 0.25)
    
  # Likelihood
  for (i in 1:N){
    y[i] ~ dnorm(mu[i], tau)        
    mu[i] &lt;- beta0
  } #i
}
```

---
## A simple linear model

`$$\Large y_{ij} = \beta_{[j]} + \epsilon_i$$`

`$$\Large \epsilon_i \sim normal(0, \tau)$$`

--
- If `\(\beta_{[1]} \perp \beta_{[2]} \perp \beta_{[3]} \perp ...\perp \beta_{[J]}\)`

--
```
model {
  # Priors
  for(j in 1:J){
    beta0[j] ~ dnorm(0, 0.33)
  }
  tau ~ dgamma(0.25, 0.25)
    
  # Likelihood
  for (i in 1:N){
    y[i] ~ dnorm(mu[i], tau)        
    mu[i] &lt;- beta0[group[j]]
  } #i
}
```
???

nb `\(\perp\)` means "independent of"

This should look familiar - it's the means parameterization of the ANOVA model

---
## A simple linear model

`$$\Large y_{ij} = \beta_{[j]} + \epsilon_i$$`

`$$\Large \epsilon_i \sim normal(0, \tau)$$`

--
- If `\(\beta_{[j]} \sim normal(\mu_{\beta0}, \tau_{\beta0})\)`

&lt;img src="Lecture8_files/figure-html/unnamed-chunk-1-1.png" style="display: block; margin: auto;" /&gt;

---
## A simple linear model

`$$\Large y_{ij} = \beta_{[j]} + \epsilon_i$$`

`$$\Large \epsilon_i \sim normal(0, \tau)$$`

--
- If `\(\beta_{[j]} \sim normal(\mu_{\beta0}, \tau_{\beta0})\)`

--
```
model {
  # Priors
  for(j in 1:J){
    beta0[j] ~ dnorm(mu.beta, tau.beta)
  }
  mu.beta ~ dnorm(0, 0.33)
  tau.beta ~ dgamma(0.25, 0.25)
  tau ~ dgamma(0.25, 0.25)
    
  # Likelihood
  for (i in 1:N){
    y[i] ~ dnorm(mu[i], tau)        
    mu[i] &lt;- beta0[group[j]]
  } #i
}
```

---
## Random effects
&lt;br/&gt;

--
- Only apply to factors  
&lt;br/&gt;

--
- Imply grouped effects  
&lt;br/&gt;

--
- Can include intercept, slope, and variance parameters  
&lt;br/&gt;

--
- Assume exchangeability  
&lt;br/&gt;

--
- Represent a compromise between total pooling `\((\beta_{0[1]}=\beta_{0[2]}=...=\beta_{0[J]})\)` and no pooling `\((\beta_{[1]} \perp \beta_{[2]} \perp ...\perp \beta_{[J]})\)`  
&lt;br/&gt;

--
- Typically require `\(&gt;5-10\)` factor levels  


---
## Random effects = hierarchical model
&lt;br/&gt;
&lt;br/&gt;


`$$\Large [\beta_{0[j]}, \mu_{\beta0}, \tau_{\beta0}, \tau|y_{ij}] = [y_{ij}|\beta_{0[j]}, \tau][\beta_{0[j]}|\mu_{\beta0}, \tau_{\beta0}][\tau][\mu_{\beta0}][\tau_{\beta0}]$$`
&lt;br/&gt;

--
- Can include multiple random effects  

- Can include fixed and random effects (mixed-models)  

- Can include multiple levels of hierarchy  

---
## Why use random effects?

1) Scope of inference  

- learn about `\(\beta_{0[j]}\)` **and** `\(\mu_{beta_0}\)`, `\(\tau_{beta_0}\)`  

- prediction to unsampled groups (in space or time)  


---
## Why use random effects?

1) Scope of inference  

2) Partitioning of variance  

- Account for variability among groups vs. among observational units

---
## Why use random effects?

1) Scope of inference  

2) Partitioning of variance  

3) Accounting for uncertainty  

- modeling `\(\tau_{beta_0}\)` recognizes uncertainty from sampling groups

---
## Why use random effects?

1) Scope of inference  

2) Partitioning of variance  

3) Accounting for uncertainty  

4) Avoiding psuedo-replication  

- Account for non-independence within groups

---
## Why use random effects?

1) Scope of inference  

2) Partitioning of variance  

3) Accounting for uncertainty  

4) Avoiding psuedo-replication  

5) Borrowing strength  

- `\(\beta_{0[j]}\)` estimating from group `\(j\)` observations + all other groups  

- "shrinkage"" towards mean  

    + degree of shrinkage inversely proportional to precision  
    
---
## Why not use random effects?

#### Always use random effects (Gelman &amp; Hill 2007)

#### but...

--
- Assumption of exchangeability  
&lt;br/&gt;

--
- Requires 5-10 levels  
&lt;br/&gt;

--
- Computationally intensive  
&lt;br/&gt;

--
- Harder to interpret
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
