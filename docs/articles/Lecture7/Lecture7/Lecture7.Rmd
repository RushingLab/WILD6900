---
title: "Lecture 7"
subtitle: "Hierarchical models and GLM review"
author: "<br/><br/><br/>WILD6900 (Spring 2019)"
output:
  xaringan::moon_reader:
    css: ["default", "WILD6900.css", "WILD6900-fonts.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center', warning=FALSE, message=FALSE)
library(WILD6900)
library(gganimate)
```

## Readings

---
class: inverse, center, middle

# From linear models to GLMs

---
# Linear models
<br/>
<br/>
$$\Large response = deterministic\; part+stochastic\; part$$ 
<br/>
<br/>

--
$$\underbrace{\LARGE \mu_i = \alpha + \beta \times x_i}_{Deterministic}$$
<br/>
<br/>

--
$$\underbrace{\LARGE y_i \sim Normal(\mu_i, \tau)}_{Stochastic}$$  

???

Note that the deterministic portion of the model has the same form as the equation for a line: $y = a + b \times x$, which is why we call these linear models

---
class: inverse, middle, center

# Linear models under the hood
## Variations on the determinstic model

---
# A simple linear model: the t-test
<br/>
<br/>
<br/>

$$\LARGE y_i = \beta_0 + \beta_1 \times x_i$$
<br/>
<br/>

--
$$\LARGE x_i \in [0,1]$$

---
# Under the hood: The t-test

```{r echo = TRUE}
head(model.matrix(lm(mpg ~ am, data = mtcars)))
```

--
### $\Large \beta_0$ is the mean mpg for automatic transmissions

--
### $\Large \beta_1$ is the *difference* between automatic and manual transmissions

???

This is called the *effects* parameterization

---
# Under the hood: The t-test

```{r eval = FALSE, echo = TRUE}
lm(mpg ~ am, data = mtcars)
```


```{r echo = FALSE}
knitr::kable(broom::tidy(lm(mpg ~ am, data = mtcars)))
```

---
# Under the hood: The t-test

```{r echo = TRUE}
head(model.matrix(lm(mpg ~ as.factor(am) - 1, data = mtcars)))
```

--
### $\Large \beta_0$ is the mean mpg for automatic transmissions

--
### $\Large \beta_1$ is the mean mpg for manual transmissions

???

This is called the *means* parameterization

---
# Under the hood: The t-test

```{r eval = FALSE, echo = TRUE}
lm(mpg ~ as.factor(am) - 1, data = mtcars)
```

```{r echo = FALSE}
mod <- broom::tidy(lm(mpg ~ as.factor(am) - 1, data = mtcars))
knitr::kable(mod)
```

---
# The t-test becomes an ANOVA

<br/>
<br/>
<br/>

$$\LARGE y_i = \beta_0 + \beta_1 \times x_i$$
<br/>
<br/>

--
$$\LARGE x_i \in [0,1,2,...,J]$$

---
# Under the hood: ANOVA

```{r echo = TRUE}
head(model.matrix(lm(mpg ~ as.factor(cyl), data = mtcars)))
```

--
### $\Large \beta_0$ is the mean mpg for 4-cylinders

--
### $\Large \beta_1$ is the *difference* between 4-cyl & 6-cyl

--
### $\Large \beta_2$ is the *difference* between 4-cyl & 8-cyl


---
# The ANOVA becomes an ANCOVA


<br/>
<br/>
<br/>

$$\LARGE y_i = \beta_0 + \beta_1 \times x1_i + \beta_2 \times x2_i $$
<br/>
<br/>

--
$$\LARGE x1_i \in [0,1,2,...,J]$$
<br/>

$$\LARGE x2_i \in [-\infty, \infty]$$

---
# Under the hood: ANCOVA

```{r echo = TRUE}
head(model.matrix(lm(mpg ~ as.factor(cyl) + hp, data = mtcars)))
```

--
$\large \beta_0$ is the mean mpg for 4-cylinders **@ 0hp**  

--
$\large \beta_1$ is the *difference* between 4-cyl & 6-cyl **@ 0hp**  

--
$\large \beta_2$ is the *difference* between 4-cyl & 8-cyl **@ 0hp**  

--
$\large \beta_3$ is the effect of hp on mpg  

---
class: inverse, middle, center

# Linear models under the hood
## Variations on the stochastic model

---
# 